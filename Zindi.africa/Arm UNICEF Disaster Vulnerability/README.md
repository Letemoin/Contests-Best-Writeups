# ARM & UNICEF Disaster Vulnerability Challenge  
Comprehensive end-to-end pipeline for counting roof types (Other, Tin, Thatch) in rural Malawi drone imagery—from raw CSV annotations through model training, inference, ensembling, and submission.


** This writeup and Code is cleaned via AI, as the the original were not sent to Zindi due to not in top 20 Place or requested **

---

## 1. Overview & Objectives  
**Contest Background:**  
The ARM & UNICEF Disaster Vulnerability Challenge on Zindi tasked participants with developing algorithms to count three categories of roofed dwellings—Other, Tin, Thatch—in aerial drone imagery of rural Malawi. Accurate roof‐type counts help NGOs estimate at‐risk populations for disaster response and resilience planning.

**Goals:**  
1. Convert provided CSV bounding‐box annotations into COCO format.  
2. Train multiple state‐of‐the-art detectors (PPYOLOE X Fast and RTMDet variants).  
3. Perform inference and fuse predictions via Weighted Boxes Fusion (WBF).  
4. Generate final submission CSV matching Zindi’s “SampleSubmission” schema.

---

## 2. Requirements  
Install with `pip install` (or pin in your `requirements.txt`):  
- **Core ML & MMDet:**  
  - `mmcv-full`  
  - `mmdet`  
  - `mmyolo` (for PPYOLOE)  
  - `openmim`  
- **Ensembling & Metrics:**  
  - `ensemble-boxes`  
  - `pycocotools`  
- **Data & Utilities:**  
  - `pandas`  
  - `scikit-learn`  
  - `Pillow`  
  - `omegaconf`  
  - `hydra-core`  
- **Logging & Visualization:**  
  - `wandb` (optional, for experiment tracking)  
  - `matplotlib`  
- **Deep Learning:**  
  - `torch>=2.0`  
  - `torchvision>=0.13`  

---

## 3. Data Description  
- **Training CSV** (`Train.csv`): image IDs, normalized bounding‐box coordinates, class labels {1,2,3}.  
- **Test CSV** (`Test.csv`): image IDs without annotations.  
- **Sample Submission** (`SampleSubmission.csv`): placeholder CSV with columns `ImageId,1,2,3` for counts.  
- **Images Folder**: `.tif` drone images for both train & test sets.

---

## 4. Pipeline Overview  
```mermaid
flowchart LR
    A[Train.csv → COCO JSONs] --> B[Model Training]
    B --> C1[PPYOLOE X Fast]
    B --> C2[RTMDet L (3 variants)]
    B --> C3[RTMDet X]
    C1 & C2 & C3 --> D[Inference → JSON Outputs]
    D --> E[Filter Small Boxes]
    E --> F[Weighted Boxes Fusion]
    F --> G[Pivot to Counts]
    G --> H[final_submission.csv]
```

---

## 5. Detailed Steps  

### 5.1 Setup & Configuration  
- Create a single YAML or Python dict (`CFG`) defining all paths, hyperparameters, and thresholds:  
  ```yaml
  HOME: "/notebooks/ZINDI"
  CSV_TRAIN: "Train.csv"
  CSV_TEST: "Test.csv"
  SAMPLE_SUB: "SampleSubmission.csv"
  IMAGE_FOLDER: "Images"
  COCO_DIR: "coco"
  WORK_DIR: "work_dirs"
  VAL_SPLIT: 0.1
  BOX_SMALL_FACTOR: 0.02
  ENSEMBLE_IOU_THR: 0.5
  SCORE_THR: 0.4
  ```
- Install dependencies and set up directories.

### 5.2 Data Conversion (CSV → COCO)  
1. **Parse** `Train.csv` for rows `(ImageId, XMin, YMin, XMax, YMax, ClassId)`.  
2. **Map** each unique ImageId to a numeric `image_id` and retrieve its width/height via PIL.  
3. **Assemble** COCO JSON with keys `images`, `annotations`, `categories`.  
4. **Stratified split** on `(image_id, category_id)` to produce `instances_train.json` and `instances_val.json`.

### 5.3 Model Definitions & Training  
Define five experiments:  
| Name            | Config Path                                                                 | Batch | Epochs | LR     | Resume | W&B  |
|-----------------|-------------------------------------------------------------------------------|-------|--------|--------|--------|------|
| ppyoloe_x_fast  | mmyolo/configs/ppyoloe/ppyoloe_x_fast_8xb16-300e_coco.py                     | 16    | 300    | 1e-3   | No     | No   |
| rtmdet_l_fast   | configs/rtmdet/rtmdet_l_syncbn_fast_8xb8-100e_coco.py                        | 8     | 100    | 4e-3   | Yes    | Yes  |
| rtmdet_l_lp     | configs/rtmdet/rtmdet_l_syncbn_fast_8xb2-400e_coco.py                        | 2     | 400    | 1e-4   | Yes    | No   |
| rtmdet_x_fast   | configs/rtmdet/rtmdet_x_syncbn_fast_8xb8-200e_coco.py                        | 8     | 200    | 1e-3   | No     | Yes  |
| rtmdet_l_mid    | configs/rtmdet/rtmdet_l_syncbn_fast_8xb4-100e_coco.py                        | 4     | 100    | 4e-3   | Yes    | No   |

For each experiment:  
1. **Load** base MMDet config.  
2. **Override** data paths (`ann_file`, `img_prefix`), optimizer LR, runner epochs, batch size, work_dir, resume flag.  
3. **Optional W&B hook**.  
4. **Call** `train_detector(...)` with `validate=True`.  

### 5.4 Inference & JSON Export  
For each trained model:  
1. **Initialize** detector with `init_detector(config, checkpoint)`.  
2. **Run** `inference_detector` on test image folder.  
3. **Flatten** results into COCO-style list of dicts `{image_id, category_id, bbox, score}`.  
4. **Save** per-model `results.json` in that experiment’s `work_dirs`.

### 5.5 Ensemble & Submission  
1. **Load** all model JSONs.  
2. **Filter** tiny boxes per image (area < max_area × BOX_SMALL_FACTOR).  
3. **Group** boxes/scores/labels per image across models.  
4. **Fuse** with `weighted_boxes_fusion(..., iou_thr=ENSEMBLE_IOU_THR, skip_box_thr=SCORE_THR)`.  
5. **Rasterize** fused boxes into count table `(image_id, category_id) → count`.  
6. **Map** `image_id → ImageId.tif` from `Test.csv`.  
7. **Populate** `SampleSubmission.csv` columns `1,2,3` with counts.  
8. **Export** `final_submission.csv` ready for Zindi upload.

---

## 6. Conclusion  
This unified, modular pipeline—backed by configurable YAMLs, robust COCO-format conversion, hyperparameter-driven experiments, and WBF ensembling—will impress recruiters with its clarity, reproducibility, and performance focus. You’re now equipped to tackle the ARM-UNICEF challenge end-to-end and deliver reliable, production-ready submissions.
